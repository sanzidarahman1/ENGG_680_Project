{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "The file which result is somehow the same as random forest.ipynb",
      "authorship_tag": "ABX9TyPzmmbJDlJo3SkgzyXViPYV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanzidarahman1/ENGG_680_Project/blob/main/The_file_which_result_is_somehow_the_same_as_random_forest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#here the new one"
      ],
      "metadata": {
        "id": "B4EsFLtwtqOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bokefS7fYEQ",
        "outputId": "7dafd6ee-564f-4b7e-821e-bacdfdb8db32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 33ms/step - loss: 0.0171 - val_loss: 0.0061\n",
            "Epoch 2/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0065 - val_loss: 0.0044\n",
            "Epoch 3/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0045 - val_loss: 0.0030\n",
            "Epoch 4/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0036 - val_loss: 0.0028\n",
            "Epoch 5/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0037 - val_loss: 0.0025\n",
            "Epoch 6/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 7/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - loss: 0.0034 - val_loss: 0.0028\n",
            "Epoch 8/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 32ms/step - loss: 0.0032 - val_loss: 0.0024\n",
            "Epoch 9/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 32ms/step - loss: 0.0032 - val_loss: 0.0029\n",
            "Epoch 10/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0030 - val_loss: 0.0035\n",
            "Epoch 11/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 12/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 0.0031 - val_loss: 0.0026\n",
            "Epoch 13/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0031 - val_loss: 0.0027\n",
            "Epoch 14/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 15/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - loss: 0.0030 - val_loss: 0.0028\n",
            "Epoch 16/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - loss: 0.0030 - val_loss: 0.0026\n",
            "Epoch 17/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0029 - val_loss: 0.0025\n",
            "Epoch 18/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0029 - val_loss: 0.0024\n",
            "Epoch 19/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 20/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - loss: 0.0030 - val_loss: 0.0023\n",
            "Epoch 21/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 22/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 23/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 24/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 25/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 26/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 27/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 0.0028 - val_loss: 0.0023\n",
            "Epoch 28/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0027 - val_loss: 0.0023\n",
            "Epoch 29/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0028 - val_loss: 0.0025\n",
            "Epoch 30/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0028 - val_loss: 0.0026\n",
            "Epoch 31/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0025\n",
            "Epoch 32/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 33/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 0.0028 - val_loss: 0.0024\n",
            "Epoch 34/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0027 - val_loss: 0.0022\n",
            "Epoch 35/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 36/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - loss: 0.0027 - val_loss: 0.0024\n",
            "Epoch 37/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 38/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - loss: 0.0028 - val_loss: 0.0020\n",
            "Epoch 39/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0023\n",
            "Epoch 40/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 41/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - loss: 0.0025 - val_loss: 0.0023\n",
            "Epoch 42/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 31ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 43/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - loss: 0.0023 - val_loss: 0.0022\n",
            "Epoch 44/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 45/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0023 - val_loss: 0.0025\n",
            "Epoch 46/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 33ms/step - loss: 0.0026 - val_loss: 0.0022\n",
            "Epoch 47/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 34ms/step - loss: 0.0025 - val_loss: 0.0021\n",
            "Epoch 48/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 32ms/step - loss: 0.0023 - val_loss: 0.0020\n",
            "Epoch 49/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - loss: 0.0025 - val_loss: 0.0020\n",
            "Epoch 50/50\n",
            "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 32ms/step - loss: 0.0023 - val_loss: 0.0021\n",
            "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step\n",
            "LSTM Model Performance on Test Data:\n",
            "Mean Squared Error (MSE): 4345.412321012434\n",
            "Mean Absolute Error (MAE): 38.55980659415329\n",
            "Root Mean Squared Error (RMSE): 65.91974151202683\n",
            "R-squared (R²): 0.9212087660121138\n",
            "Enter Temperature (C): 24.8\n",
            "Enter Daily Precipitation (mm): 0\n",
            "Enter Wind Speed (km/h): 4\n",
            "Is it a weekend or holiday? (y/n): n\n",
            "Is it during Stampede? (y/n): n\n",
            "Enter Day Type (Sunny/Rainy/Snowy): Sunny\n",
            "Enter Date and Time (YYYY-MM-DD HH:MM:SS): 2024-07-31 22:00:00\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282ms/step\n",
            "Predicted Vehicle Count: 486.9979248046875\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Step 1: Load and Preprocess the Data\n",
        "data = pd.read_excel('combined_data_final_EB (1) (1).xlsx')\n",
        "\n",
        "# Convert 'date' and 'time' columns to datetime and extract features\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
        "data['hour'] = data['time'].dt.hour\n",
        "data['minute'] = data['time'].dt.minute\n",
        "\n",
        "# Encode categorical columns\n",
        "data['day type'] = data['Day_Type'].map({'Sunny': 0, 'Rainy': 1, 'Snowy': 2})\n",
        "data['weekend/holiday (y/n)'] = data['weekend/holiday (y/n)'].map({'y': 1, 'n': 0})\n",
        "data['stampede (y/n)'] = data['stampede (y/n)'].map({'y': 1, 'n': 0})\n",
        "\n",
        "# Convert 'date' to numerical features\n",
        "data['day_of_year'] = data['date'].dt.dayofyear\n",
        "data['time_minutes'] = data['hour'] * 60 + data['minute']\n",
        "\n",
        "# Define features and target variable\n",
        "features = ['day_of_year', 'time_minutes', 'weekend/holiday (y/n)', 'stampede (y/n)',\n",
        "            'temp. (C)', 'daily precip. (mm)', 'wind (km/h)', 'day type']\n",
        "X = data[features]\n",
        "y = data['vehicle count']\n",
        "\n",
        "# Scale features and target separately\n",
        "scaler_X = MinMaxScaler()\n",
        "X_scaled = scaler_X.fit_transform(X)\n",
        "scaler_y = MinMaxScaler()\n",
        "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
        "\n",
        "# Prepare data for LSTM (creating sequences of past observations)\n",
        "sequence_length = 24  # e.g., 24-hour sequence\n",
        "X_lstm, y_lstm = [], []\n",
        "for i in range(sequence_length, len(X_scaled)):\n",
        "    X_lstm.append(X_scaled[i - sequence_length:i])\n",
        "    y_lstm.append(y_scaled[i])\n",
        "\n",
        "X_lstm, y_lstm = np.array(X_lstm), np.array(y_lstm)\n",
        "\n",
        "# Step 2: Split Data into Training and Test Sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=35)\n",
        "\n",
        "# Step 3: Build the LSTM Model\n",
        "model = Sequential([\n",
        "    LSTM(100, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.2),\n",
        "    LSTM(50, return_sequences=False),\n",
        "    Dropout(0.2),\n",
        "    Dense(1)  # Output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=1)\n",
        "\n",
        "# Step 4: Evaluate the Model on the Test Set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Inverse transform predictions and actual values to original scale\n",
        "y_test_rescaled = scaler_y.inverse_transform(y_test)\n",
        "y_pred_rescaled = scaler_y.inverse_transform(y_pred)\n",
        "\n",
        "# Calculate metrics\n",
        "test_mse = mean_squared_error(y_test_rescaled, y_pred_rescaled)\n",
        "test_mae = mean_absolute_error(y_test_rescaled, y_pred_rescaled)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test_rescaled, y_pred_rescaled)\n",
        "\n",
        "print(\"LSTM Model Performance on Test Data:\")\n",
        "print(f\"Mean Squared Error (MSE): {test_mse}\")\n",
        "print(f\"Mean Absolute Error (MAE): {test_mae}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {test_rmse}\")\n",
        "print(f\"R-squared (R²): {test_r2}\")\n",
        "\n",
        "# Step 5: Function for User Input Prediction\n",
        "def predict_vehicle_count():\n",
        "    \"\"\"\n",
        "    Takes user input for features and returns predicted vehicle count.\n",
        "    \"\"\"\n",
        "    # Request user input for each feature\n",
        "    temp = float(input(\"Enter Temperature (C): \"))\n",
        "    precip = float(input(\"Enter Daily Precipitation (mm): \"))\n",
        "    wind = float(input(\"Enter Wind Speed (km/h): \"))\n",
        "    weekend = input(\"Is it a weekend or holiday? (y/n): \").strip().lower()\n",
        "    weekend = 1 if weekend == 'y' else 0\n",
        "    stampede = input(\"Is it during Stampede? (y/n): \").strip().lower()\n",
        "    stampede = 1 if stampede == 'y' else 0\n",
        "    day_type = input(\"Enter Day Type (Sunny/Rainy/Snowy): \").strip().capitalize()\n",
        "    day_type = {'Sunny': 0, 'Rainy': 1, 'Snowy': 2}.get(day_type, 0)\n",
        "\n",
        "    # Extract day and time from user-provided date (assuming YYYY-MM-DD format)\n",
        "    date_str, time_str = input(\"Enter Date and Time (YYYY-MM-DD HH:MM:SS): \").split()\n",
        "    date = pd.to_datetime(date_str)\n",
        "    time = pd.to_datetime(time_str, format='%H:%M:%S')\n",
        "\n",
        "    # Calculate day_of_year and time_minutes\n",
        "    day_of_year = date.dayofyear\n",
        "    time_minutes = time.hour * 60 + time.minute\n",
        "\n",
        "    # Prepare input data in the correct format\n",
        "    input_data = pd.DataFrame([[day_of_year, time_minutes, weekend, stampede, temp, precip, wind, day_type]], columns=features)\n",
        "    input_scaled = scaler_X.transform(input_data)\n",
        "\n",
        "    # Create the sequence expected by the LSTM model\n",
        "    input_sequence = np.array([input_scaled[-sequence_length:]])  # Ensure it has the right shape\n",
        "\n",
        "    # Make prediction\n",
        "    predicted_scaled = model.predict(input_sequence)\n",
        "    predicted_count = scaler_y.inverse_transform(predicted_scaled)[0][0]\n",
        "    print(f\"Predicted Vehicle Count: {predicted_count}\")\n",
        "\n",
        "# Run the function to get a prediction\n",
        "predict_vehicle_count()\n"
      ]
    }
  ]
}